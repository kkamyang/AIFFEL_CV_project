{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[CV_09]semantic_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "55mJ6DpXB0pp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lTH8C88S-Eq7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from glob import glob\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from albumentations import  HorizontalFlip, RandomSizedCrop, Compose, OneOf, Resize\n",
        "\n",
        "def build_augmentation(is_train=True):\n",
        "  if is_train:    # 훈련용 데이터일 경우\n",
        "    return Compose([\n",
        "                    HorizontalFlip(p=0.5),    # 50%의 확률로 좌우대칭\n",
        "                    RandomSizedCrop(         # 50%의 확률로 RandomSizedCrop\n",
        "                        min_max_height=(300, 370),\n",
        "                        w2h_ratio=370/1242,\n",
        "                        height=224,\n",
        "                        width=224,\n",
        "                        p=0.5\n",
        "                        ),\n",
        "                    Resize(              # 입력이미지를 224X224로 resize\n",
        "                        width=224,\n",
        "                        height=224\n",
        "                        )\n",
        "                    ])\n",
        "  return Compose([      # 테스트용 데이터일 경우에는 224X224로 resize만 수행 \n",
        "                Resize(\n",
        "                    width=224,\n",
        "                    height=224\n",
        "                    )\n",
        "                ])"
      ],
      "metadata": {
        "id": "3ezCFd9l-oFv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = os.getenv('HOME')+'/aiffel/semantic_segmentation/data/training'\n",
        "\n",
        "augmentation_train = build_augmentation()\n",
        "augmentation_test = build_augmentation(is_train=False)\n",
        "input_images = glob(os.path.join(dir_path, \"image_2\", \"*.png\"))\n",
        "\n",
        "# 훈련 데이터셋에서 5개만 가져와 augmentation을 적용  \n",
        "plt.figure(figsize=(12, 20))\n",
        "for i in range(5):\n",
        "    image = imread(input_images[i]) \n",
        "    image_data = {\"image\":image}\n",
        "    resized = augmentation_test(**image_data)\n",
        "    processed = augmentation_train(**image_data)\n",
        "    plt.subplot(5, 2, 2*i+1)\n",
        "    plt.imshow(resized[\"image\"])  # 왼쪽이 원본이미지\n",
        "    plt.subplot(5, 2, 2*i+2)\n",
        "    plt.imshow(processed[\"image\"])  # 오른쪽이 augment된 이미지\n",
        "  \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UeGm9TIi-tSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from albumentations import  HorizontalFlip, RandomSizedCrop, Compose, OneOf, Resize\n",
        "\n",
        "def build_augmentation(is_train=True):\n",
        "  if is_train:    # 훈련용 데이터일 경우\n",
        "    return Compose([\n",
        "                    HorizontalFlip(p=0.5),    # 50%의 확률로 좌우대칭\n",
        "                    RandomSizedCrop(         # 50%의 확률로 RandomSizedCrop\n",
        "                        min_max_height=(300, 370),\n",
        "                        w2h_ratio=370/1242,\n",
        "                        height=224,\n",
        "                        width=224,\n",
        "                        p=0.5\n",
        "                        ),\n",
        "                    Resize(              # 입력이미지를 224X224로 resize\n",
        "                        width=224,\n",
        "                        height=224\n",
        "                        )\n",
        "                    ])\n",
        "  return Compose([      # 테스트용 데이터일 경우에는 224X224로 resize만 수행\n",
        "                Resize(\n",
        "                    width=224,\n",
        "                    height=224\n",
        "                    )\n",
        "                ])"
      ],
      "metadata": {
        "id": "QpbqROEKBCXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = os.getenv('HOME')+'/aiffel/semantic_segmentation/data/training'\n",
        "\n",
        "augmentation_train = build_augmentation()\n",
        "augmentation_test = build_augmentation(is_train=False)\n",
        "input_images = glob(os.path.join(dir_path, \"image_2\", \"*.png\"))\n",
        "\n",
        "# 훈련 데이터셋에서 5개만 가져와 augmentation을 적용  \n",
        "plt.figure(figsize=(12, 20))\n",
        "for i in range(5):\n",
        "    image = imread(input_images[i]) \n",
        "    image_data = {\"image\":image}\n",
        "    resized = augmentation_test(**image_data)\n",
        "    processed = augmentation_train(**image_data)\n",
        "    plt.subplot(5, 2, 2*i+1)\n",
        "    plt.imshow(resized[\"image\"])  # 왼쪽이 원본이미지\n",
        "    plt.subplot(5, 2, 2*i+2)\n",
        "    plt.imshow(processed[\"image\"])  # 오른쪽이 augment된 이미지\n",
        "  \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8mkUbZLNBFEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KittiGenerator(tf.keras.utils.Sequence):\n",
        "  '''\n",
        "  KittiGenerator는 tf.keras.utils.Sequence를 상속받음\n",
        "  우리가 KittiDataset을 원하는 방식으로 preprocess하기 위해서 Sequnce를 커스텀해 사용\n",
        "  '''\n",
        "  def __init__(self, \n",
        "               dir_path,\n",
        "               batch_size=16,\n",
        "               img_size=(224, 224, 3),\n",
        "               output_size=(224, 224),\n",
        "               is_train=True,\n",
        "               augmentation=None):\n",
        "    '''\n",
        "    dir_path: dataset의 directory path\n",
        "    batch_size: batch_size\n",
        "    img_size: preprocess에 사용할 입력이미지의 크기\n",
        "    output_size: ground_truth를 만들어주기 위한 크기\n",
        "    is_train: 이 Generator가 학습용인지 테스트용인지 구분\n",
        "    augmentation: 적용하길 원하는 augmentation 함수를 인자로 받음\n",
        "    '''\n",
        "    self.dir_path = dir_path\n",
        "    self.batch_size = batch_size\n",
        "    self.is_train = is_train\n",
        "    self.dir_path = dir_path\n",
        "    self.augmentation = augmentation\n",
        "    self.img_size = img_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # load_dataset()을 통해서 kitti dataset의 directory path에서 라벨과 이미지를 확인\n",
        "    self.data = self.load_dataset()\n",
        "\n",
        "  def load_dataset(self):\n",
        "    # kitti dataset에서 필요한 정보(이미지 경로 및 라벨)를 directory에서 확인하고 로드하는 함수\n",
        "    # 이때 is_train에 따라 test set을 분리해서 load하도록 해야함\n",
        "    input_images = glob(os.path.join(self.dir_path, \"image_2\", \"*.png\"))\n",
        "    label_images = glob(os.path.join(self.dir_path, \"semantic\", \"*.png\"))\n",
        "    input_images.sort()\n",
        "    label_images.sort()\n",
        "    assert len(input_images) == len(label_images)\n",
        "    data = [ _ for _ in zip(input_images, label_images)]\n",
        "\n",
        "    if self.is_train:\n",
        "      return data[:-30]\n",
        "    return data[-30:]\n",
        "    \n",
        "  def __len__(self):\n",
        "    # Generator의 length로서 전체 dataset을 batch_size로 나누고 소숫점 첫째자리에서 올림한 값을 반환\n",
        "    return math.ceil(len(self.data) / self.batch_size)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # 입력과 출력을 만듦\n",
        "    # 입력은 resize및 augmentation이 적용된 input image이고 \n",
        "    # 출력은 semantic label\n",
        "    batch_data = self.data[\n",
        "                           index*self.batch_size:\n",
        "                           (index + 1)*self.batch_size\n",
        "                           ]\n",
        "    inputs = np.zeros([self.batch_size, *self.img_size])\n",
        "    outputs = np.zeros([self.batch_size, *self.output_size])\n",
        "        \n",
        "    for i, data in enumerate(batch_data):\n",
        "      input_img_path, output_path = data\n",
        "      _input = imread(input_img_path)\n",
        "      _output = imread(output_path)\n",
        "      _output = (_output==7).astype(np.uint8)*1\n",
        "      data = {\n",
        "          \"image\": _input,\n",
        "          \"mask\": _output,\n",
        "          }\n",
        "      augmented = self.augmentation(**data)\n",
        "      inputs[i] = augmented[\"image\"]/255\n",
        "      outputs[i] = augmented[\"mask\"]\n",
        "      return inputs, outputs\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    # 한 epoch가 끝나면 실행되는 함수 (학습중인 경우에 순서를 random shuffle하도록 적용한 것을 볼 수 있음)\n",
        "    self.indexes = np.arange(len(self.data))\n",
        "    if self.is_train == True :\n",
        "      np.random.shuffle(self.indexes)\n",
        "      return self.indexes"
      ],
      "metadata": {
        "id": "52n-4M07BFBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation = build_augmentation()\n",
        "test_preproc = build_augmentation(is_train=False)\n",
        "        \n",
        "train_generator = KittiGenerator(\n",
        "    dir_path, \n",
        "    augmentation=augmentation,\n",
        ")\n",
        "\n",
        "test_generator = KittiGenerator(\n",
        "    dir_path, \n",
        "    augmentation=test_preproc,\n",
        "    is_train=False\n",
        ")"
      ],
      "metadata": {
        "id": "yCiHDQTUBE90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "DWDdK-noBvSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape=(224, 224, 3)):\n",
        "  inputs = Input(input_shape)\n",
        "\t\n",
        "  #Contracting Path\n",
        "  conv1 = Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='he_normal')(inputs)\n",
        "  conv1 = Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv1)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  conv2 = Conv2D(128, 3, activation='relu', padding='same',kernel_initializer='he_normal')(pool1)\n",
        "  conv2 = Conv2D(128, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "  conv3 = Conv2D(256, 3, activation='relu', padding='same',kernel_initializer='he_normal')(pool2)\n",
        "  conv3 = Conv2D(256, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv3)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "  conv4 = Conv2D(512, 3, activation='relu', padding='same',kernel_initializer='he_normal')(pool3)\n",
        "  conv4 = Conv2D(512, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv4)\n",
        "  drop4 = Dropout(0.5)(conv4)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "  \n",
        "  conv5 = Conv2D(1024, 3, activation='relu', padding='same',kernel_initializer='he_normal')(pool4)  \n",
        "  conv5 = Conv2D(1024, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv5)\n",
        "  \n",
        "  #Expanding Path\n",
        "  drop5 = Dropout(0.5)(conv5)\n",
        "  up6 = Conv2DTranspose(512, 2, activation='relu', strides=(2,2), kernel_initializer='he_normal')(drop5)\n",
        "  merge6 = concatenate([drop4,up6], axis = 3)\n",
        "  conv6 = Conv2D(512, 3, activation='relu', padding='same',kernel_initializer='he_normal')(merge6)\n",
        "  conv6 = Conv2D(512, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv6)\n",
        "  up7 = Conv2DTranspose(256, 2, activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv6)\n",
        "  merge7 = concatenate([conv3,up7], axis = 3)\n",
        "  conv7 = Conv2D(256, 3, activation='relu', padding='same',kernel_initializer='he_normal')(merge7)\n",
        "  conv7 = Conv2D(256, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv7)\n",
        "  up8 = Conv2DTranspose(128, 2, activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv7)\n",
        "  merge8 = concatenate([conv2,up8], axis = 3)\n",
        "  conv8 = Conv2D(128, 3, activation='relu', padding='same',kernel_initializer='he_normal')(merge8)\n",
        "  conv8 = Conv2D(128, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv8)\n",
        "  up9 = Conv2DTranspose(64, 2, activation='relu', strides=(2,2), kernel_initializer='he_normal')(conv8)\n",
        "  merge9 = concatenate([conv1,up9], axis = 3)\n",
        "  conv9 = Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='he_normal')(merge9)\n",
        "  conv9 = Conv2D(64, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv9)  \n",
        "  conv9 = Conv2D(2, 3, activation='relu', padding='same',kernel_initializer='he_normal')(conv9)     \n",
        "  conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "  model = Model(inputs = inputs, outputs = conv10)\n",
        "  return model"
      ],
      "metadata": {
        "id": "fZnGIqCNBE1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.getenv('HOME')+'/aiffel/semantic_segmentation/seg_model_unet.h5'\n",
        "\n",
        "model = build_model()\n",
        "model.compile(optimizer = Adam(1e-4), loss = 'binary_crossentropy')\n",
        "model.fit(\n",
        "     train_generator,\n",
        "     validation_data=test_generator,\n",
        "     steps_per_epoch=len(train_generator),\n",
        "     epochs=100,\n",
        " )\n",
        "\n",
        "model.save(model_path)  #학습한 모델을 저장"
      ],
      "metadata": {
        "id": "vneu0okdBEyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 시각화"
      ],
      "metadata": {
        "id": "IoTn3UOrBm8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 미리 준비한 모델을 불러오려면 아래 주석을 해제\n",
        "# model_path = dir_path + '/seg_model_unet.h5' \n",
        "\n",
        "model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "vGOg_HZTBXss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output(model, preproc, image_path, output_path):\n",
        "     origin_img = imread(image_path)\n",
        "     data = {\"image\":origin_img}\n",
        "     processed = preproc(**data)\n",
        "     output = model(np.expand_dims(processed[\"image\"]/255,axis=0))\n",
        "     output = (output[0].numpy()>0.5).astype(np.uint8).squeeze(-1)*255  #0.5라는 threshold를 변경하면 도로인식 결과범위가 달라짐\n",
        "     output = Image.fromarray(output)\n",
        "     background = Image.fromarray(origin_img).convert('RGBA')\n",
        "     output = output.resize((origin_img.shape[1], origin_img.shape[0])).convert('RGBA')\n",
        "     output = Image.blend(background, output, alpha=0.5)\n",
        "     output.show()\n",
        "     return output "
      ],
      "metadata": {
        "id": "BzZzoCIOBY7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#시각화한 결과를 눈으로 확인\n",
        "i = 1    # i값을 바꾸면 테스트용 파일이 달라짐 \n",
        "get_output(\n",
        "     model, \n",
        "     test_preproc,\n",
        "     image_path=dir_path + f'/image_2/00{str(i).zfill(4)}_10.png',\n",
        "     output_path=dir_path + f'./result_{str(i).zfill(3)}.png'\n",
        " )"
      ],
      "metadata": {
        "id": "fslRAGyWBb-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou_score(target, prediction):\n",
        "    intersection = np.logical_and(target, prediction)\n",
        "    union = np.logical_or(target, prediction)\n",
        "    iou_score = float(np.sum(intersection)) / float(np.sum(union))\n",
        "    print('IoU : %f' % iou_score )\n",
        "    return iou_score"
      ],
      "metadata": {
        "id": "Ob92ycPBBbmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output(model, preproc, image_path, output_path, label_path):\n",
        "    origin_img = imread(image_path)\n",
        "    data = {\"image\":origin_img}\n",
        "    processed = preproc(**data)\n",
        "    output = model(np.expand_dims(processed[\"image\"]/255,axis=0))\n",
        "    output = (output[0].numpy()>=0.5).astype(np.uint8).squeeze(-1)*255  #0.5라는 threshold를 변경하면 도로인식 결과범위가 달라짐\n",
        "    prediction = output/255   # 도로로 판단한 영역\n",
        "    \n",
        "    output = Image.fromarray(output)\n",
        "    background = Image.fromarray(origin_img).convert('RGBA')\n",
        "    output = output.resize((origin_img.shape[1], origin_img.shape[0])).convert('RGBA')\n",
        "    output = Image.blend(background, output, alpha=0.5)\n",
        "    output.show()   # 도로로 판단한 영역을 시각화\n",
        "     \n",
        "    if label_path:   \n",
        "        label_img = imread(label_path)\n",
        "        label_data = {\"image\":label_img}\n",
        "        label_processed = preproc(**label_data)\n",
        "        label_processed = label_processed[\"image\"]\n",
        "        target = (label_processed == 7).astype(np.uint8)*1   # 라벨에서 도로로 기재된 영역\n",
        "\n",
        "        return output, prediction, target\n",
        "    else:\n",
        "        return output, prediction, _"
      ],
      "metadata": {
        "id": "PUVUW3qVBgv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화한 결과를 눈으로 확인\n",
        "i = 1    # i값을 바꾸면 테스트용 파일이 달라짐 \n",
        "output, prediction, target = get_output(\n",
        "     model, \n",
        "     test_preproc,\n",
        "     image_path=dir_path + f'/image_2/00{str(i).zfill(4)}_10.png',\n",
        "     output_path=dir_path + f'./result_{str(i).zfill(3)}.png',\n",
        "     label_path=dir_path + f'/semantic/00{str(i).zfill(4)}_10.png'\n",
        " )\n",
        "\n",
        "calculate_iou_score(target, prediction)"
      ],
      "metadata": {
        "id": "dLLrr03eBi5f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}